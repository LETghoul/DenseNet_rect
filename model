import torch
import torch.nn as nn
import numpy as np
import pickle
from PIL import Image

import os
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'

def record_drop():
    # feature_map的通道数都是64,提取率为0.5,所以记录cat的32个特征图index, index的取值范围为(0~63),一个样本会记录32个index数据
    feature_arch = {'D1': {'layer': torch.zeros(6, 32),
                           'index': np.array([sorted(np.random.choice(64, 32, replace=False)) for i in range(6 + 1)])},
                    'D2': {'layer': torch.zeros(12, 32),
                           'index': np.array([sorted(np.random.choice(64, 32, replace=False)) for i in range(12 + 1)])},
                    'D3': {'layer': torch.zeros(24, 32),
                           'index': np.array([sorted(np.random.choice(64, 32, replace=False)) for i in range(24 + 1)])},
                    'D4': {'layer': torch.zeros(16, 32),
                           'index': np.array([sorted(np.random.choice(64, 32, replace=False)) for i in range(16 + 1)])}}
    name_list = ['D1', 'D2', 'D3', 'D4']
    for i in name_list:
        feature_arch[i]['index'][-1] = np.array(
            [x for x in range(64) if not np.equal(x, feature_arch[i]['index'][0]).any()])
    return feature_arch
def feature_drop(x, drop_list, device):
    feature_drop = torch.zeros(x.shape[0], len(drop_list), x.shape[-2], x.shape[-1])
    for batch in range(x.shape[0]):
        for channel in range(len(drop_list)):
            feature_drop[batch][channel] = x[batch][drop_list[channel]]
    return feature_drop.to(device)
def batch_resize(batch):
    data_resize = np.zeros((batch.shape[0], 224, 224, 3), dtype=np.float64)
    for i in range(batch.shape[0]):
        img = batch[i]
        img = Image.fromarray(np.uint8(img.transpose((1, 2, 0))))     # PIL处理图像数据时的格式是（width,height,channel），而原始数据的格式是（channel， width,height）
        img = np.array(img.resize((224, 224), Image.BICUBIC))
        data_resize[i] = img
    data_resize = data_resize.transpose(0, 3, 1, 2)
    return data_resize
class Dense_Rect(nn.Module):
    def __init__(self, hidden_size, classes, device):
        super(Dense_Rect, self).__init__()
        self.device = device
        self.full_conn = nn.Linear(hidden_size, classes)
        self.first = nn.Sequential(
            nn.Conv2d(3, 64, 7, stride=1, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=3, stride=2, return_indices=True, ceil_mode=True)
        )
        self.Dense = nn.Sequential(
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(64, 128, 1, stride=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(128, 32, 3, stride=1, padding=1)
        )
        self.Transition = nn.Sequential(
            nn.BatchNorm2d(96),
            nn.ReLU(),
            nn.Conv2d(96, 64, 1, stride=1),
            nn.AvgPool2d(kernel_size=2, stride=2),
        )
        self.global_pool = nn.AvgPool2d(kernel_size=7, stride=1)
        self.feature_arch = record_drop()
    def forward(self, data):
        out = self.first(data)
        # D1
        complement_feature = feature_drop(out[0], self.feature_arch['D1']['index'][-1], self.device)
        for i in range(6):
            cat_feature = feature_drop(out[0], self.feature_arch['D1']['index'][i], self.device)
            inp = out[0]
            out = self.Dense(inp)
            out = torch.cat([out, cat_feature], dim=1)
        out = torch.cat([out[0], complement_feature], dim=1)
        # T1
        out = self.Transition(out[0])
        # D2
        complement_feature = feature_drop(out[0], self.feature_arch['D2']['index'][-1], self.device)
        for i in range(12):
            cat_feature = feature_drop(out[0], self.feature_arch['D2']['index'][i], self.device)
            out = self.Dense(out[0])
            out = torch.cat([out[0], cat_feature], dim=1)
        out = torch.cat([out[0], complement_feature], dim=1)
        # T2
        out = self.Transition(out[0])
        # D3
        complement_feature = feature_drop(out[0], self.feature_arch['D3']['index'][-1], self.device)
        for i in range(24):
            cat_feature = feature_drop(out[0], self.feature_arch['D3']['index'][i], self.device)
            out = self.Dense(out[0])
            out = torch.cat([out[0], cat_feature], dim=1)
        out = torch.cat([out[0], complement_feature], dim=1)
        # T3
        out = self.Transition(out[0])
        # D4
        complement_feature = feature_drop(out[0], self.feature_arch['D4']['index'][-1], self.device)
        for i in range(16):
            cat_feature = feature_drop(out[0], self.feature_arch['D4']['index'][i], self.device)
            out = self.Dense(out[0])
            out = torch.cat([out[0], cat_feature], dim=1)
        out = torch.cat([out[0], complement_feature], dim=1)

        out = self.global_pool(out[0])
        out = torch.flatten(out, 1)
        out = self.full_conn(out[0])
        return out

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
epoch = 400

for i in range(400):
    model = Dense_Rect(96, 10, device).to(device)
    criterion = nn.CrossEntropyLoss().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

    file = open(r'C:\Users\Administrator\pyprojects\python_pickle\CIFAR10_mini.pickle', 'rb')
    info = pickle.load(file)

    data = info['x_train']
    label = info['y_train']

    train = torch.tensor(batch_resize(data[0:20])).float().to(device)
    label = torch.tensor(label[0:20]).float().to(device)
    # 查看GPU使用情况
    print(torch.cuda.memory_allocated())
    print(torch.cuda.memory_reserved())

    with torch.no_grad():
        outputs = model(train)
    loss = criterion(outputs, label)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

