import torch
import torch.nn as nn
import numpy as np
import pickle
from PIL import Image
def record_drop():
    # feature_map的通道数都是64,提取率为0.5,所以记录cat的32个特征图index, index的取值范围为(0~63),一个样本会记录32个index数据
    feature_arch = {'D1': {'layer': torch.zeros(6, 32),
                           'index': np.array([sorted(np.random.choice(64, 32, replace=False)) for i in range(6 + 1)])},
                    'D2': {'layer': torch.zeros(12, 32),
                           'index': np.array([sorted(np.random.choice(64, 32, replace=False)) for i in range(12 + 1)])},
                    'D3': {'layer': torch.zeros(24, 32),
                           'index': np.array([sorted(np.random.choice(64, 32, replace=False)) for i in range(24 + 1)])},
                    'D4': {'layer': torch.zeros(16, 32),
                           'index': np.array([sorted(np.random.choice(64, 32, replace=False)) for i in range(16 + 1)])}}
    name_list = ['D1', 'D2', 'D3', 'D4']
    for i in name_list:
        feature_arch[i]['index'][-1] = np.array(
            [x for x in range(64) if not np.equal(x, feature_arch[i]['index'][0]).any()])
    return feature_arch
def feature_drop(x, drop_list):
    feature_drop = np.zeros((len(drop_list), x.shape[1], x.shape[2]))
    for i in range(len(drop_list)):
        feature_drop[i] = x[drop_list[i]]
    return feature_drop
def batch_resize(batch):
    data_resize = np.zeros((1000, 224, 224, 3))
    for i in range(1000):
        img = batch[i]
        img = Image.fromarray(np.uint8(img.transpose((1, 2, 0))))     # PIL处理图像数据时的格式是（width,height,channel），而原始数据的格式是（channel， width,height）
        img = np.array(img.resize((224, 224), Image.BICUBIC))
        data_resize[i] = img
    data_resize = data_resize.transpose(0, 3, 1, 2)
    return data_resize
class Dense_Rect(nn.Module):
    def __init__(self, hidden_size, classes):
        super(Dense_Rect, self).__init__()
        self.full_conn = nn.Linear(hidden_size, classes)
        self.first = nn.Sequential(
            nn.Conv2d(3, 64, 7, stride=1, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=3, stride=2, return_indices=True, ceil_mode=True)

        )
        self.Dense = nn.Sequential(
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, stride=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(128, 32, 3, stride=1)
        )
        self.Transition = nn.Sequential(
            nn.BatchNorm2d(96),
            nn.ReLU(),
            nn.Conv2d(96, 64, 1, stride=1),
            nn.AvgPool2d(kernel_size=2, stride=2),
        )
        self.global_pool = nn.AvgPool2d(kernel_size=7, stride=1)
        self.feature_arch = record_drop()
    def forward(self, data):
        out = self.first(data)
        # D1
        complement_feature = feature_drop(out, self.feature_arch['D1']['index'][-1])
        for i in range(6):
            cat_feature = feature_drop(out, self.feature_arch['D1']['index'][i])
            out = self.Dense(out)
            out = torch.cat([out, cat_feature], dim=1)
        out = torch.cat([out, complement_feature], dim=1)
        # T1
        out = self.Transition(out)
        # D2
        complement_feature = feature_drop(out, self.feature_arch['D2']['index'][-1])
        for i in range(12):
            cat_feature = feature_drop(out, self.feature_arch['D2']['index'][i])
            out = self.Dense(out)
            out = torch.cat([out, cat_feature], dim=1)
        out = torch.cat([out, complement_feature], dim=1)
        # T2
        out = self.Transition(out)
        # D3
        complement_feature = feature_drop(out, self.feature_arch['D3']['index'][-1])
        for i in range(24):
            cat_feature = feature_drop(out, self.feature_arch['D3']['index'][i])
            out = self.Dense(out)
            out = torch.cat([out, cat_feature], dim=1)
        out = torch.cat([out, complement_feature], dim=1)
        # T3
        out = self.Transition(out)
        # D4
        complement_feature = feature_drop(out, self.feature_arch['D4']['index'][-1])
        for i in range(16):
            cat_feature = feature_drop(out, self.feature_arch['D4']['index'][i])
            out = self.Dense(out)
            out = torch.cat([out, cat_feature], dim=1)
        out = torch.cat([out, complement_feature], dim=1)

        out = self.global_pool(out)
        out = torch.flatten(out, 1)
        out = self.full_conn(out)
        return out

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
epoch = 400
for i in range(400):
    model = Dense_Rect(96, 10).to(device)
    criterion = nn.CrossEntropyLoss().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

    file = open(r'C:\Users\Administrator\pyprojects\python_pickle\CIFAR10.pickle', 'rb')
    info = pickle.load(file)

    data = info['x_train']
    label = info['y_train']
    train = torch.tensor(batch_resize(data[0:1000])).to(device)
    label = torch.tensor(label[0:1000]).to(device)
    outputs = model(train)
    loss = criterion(outputs, label)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()




